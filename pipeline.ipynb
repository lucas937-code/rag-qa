{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from src.config import LocalConfig, ColabConfig, is_colab, OllamaConfig\n",
    "\n",
    "USE_OLLAMA = True\n",
    "\n",
    "if USE_OLLAMA:\n",
    "    OLLAMA_HOST = \"172.19.176.1\"\n",
    "    OLLAMA_PORT = 11434\n",
    "    OLLAMA_URL = f\"http://{OLLAMA_HOST}:{OLLAMA_PORT}/api/chat\"\n",
    "    config = OllamaConfig(embedding_model=\"BAAI/bge-base-en\", ollama_url=OLLAMA_URL)\n",
    "else:\n",
    "    config = ColabConfig(embedding_model=\"BAAI/bge-base-en\") if is_colab() else LocalConfig(embedding_model=\"BAAI/bge-base-en\")\n",
    "\n",
    "print(\"Using configuration:\", type(config).__name__)\n",
    "print(\"Base directory:\", config.BASE_DIR)\n",
    "\n",
    "config.ensure_dirs()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import datasets\n",
    "\n",
    "# Single cell: safe to run on a fresh environment\n",
    "from src.load_data import ensure_data_available\n",
    "\n",
    "# ‚úÖ Creates folders if missing and downloads only if needed\n",
    "ensure_data_available(config=config)\n",
    "\n",
    "print(\"üöÄ Dataset ready\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Single cell to explore dataset shards\n",
    "from src.explore_data import load_shards, explore_dataset\n",
    "\n",
    "# Load first few shards to save memory\n",
    "train_ds = load_shards(config.TRAIN_DIR, max_shards=3)\n",
    "val_ds   = load_shards(config.VAL_DIR, max_shards=3)\n",
    "test_ds  = load_shards(config.TEST_DIR, max_shards=3)\n",
    "\n",
    "# Explore datasets\n",
    "explore_dataset(train_ds, \"Train set\")\n",
    "explore_dataset(val_ds, \"Validation set\")\n",
    "explore_dataset(test_ds, \"Test set\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from src.analyze_data import load_shards_concat, dataset_info, analyze_lengths, most_common_answers, print_sample_qa\n",
    "\n",
    "# Load datasets\n",
    "train_ds = load_shards_concat(config.TRAIN_DIR)\n",
    "val_ds   = load_shards_concat(config.VAL_DIR)\n",
    "test_ds  = load_shards_concat(config.TEST_DIR)\n",
    "\n",
    "# Explore datasets and save plots in the 'plots/' folder\n",
    "# for name, ds in [(\"Train\", train_ds), (\"Validation\", val_ds), (\"Test\", test_ds)]:\n",
    "#     if ds is None:\n",
    "#         print(f\"No dataset found for {name}\")\n",
    "#         continue\n",
    "#     dataset_info(ds, name)\n",
    "#     analyze_lengths(ds, \"question\", name)\n",
    "#     analyze_lengths(ds, \"answer\", name)\n",
    "#     most_common_answers(ds)\n",
    "#     print_sample_qa(ds, name, n=5)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from src.compute_embeddings import compute_embeddings, retrieve_top_k\n",
    "\n",
    "# Compute embeddings (will load from file if already exists)\n",
    "corpus, corpus_embeddings = compute_embeddings(config=config)\n",
    "print(\"embeddings loaded\")\n",
    "# Test retrieval\n",
    "query = \"What is the capital of france?\"\n",
    "results, scores = retrieve_top_k(query=query, corpus=corpus, corpus_embeddings=corpus_embeddings, config=config, top_k=3)\n",
    "\n",
    "print(\"\\nTop 3 retrieved passages for query:\")\n",
    "for passage, score in zip(results, scores):\n",
    "    print(f\"[score: {score:.4f}] {passage}\\n---\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from src.generator import load_embeddings, generate_answer_combined\n",
    "\n",
    "corpus, emb = load_embeddings(config=config)\n",
    "\n",
    "query = \"What is the capital of france?\"\n",
    "answer, ctx = generate_answer_combined(query, corpus, emb, config=config, top_k=5)\n",
    "\n",
    "print(\"\\nüîç Used Context Passages:\\n\")\n",
    "for i,p in enumerate(ctx,1):\n",
    "    print(f\"{i}. {p[:200].replace(chr(10),' ')}...\\n\")\n",
    "\n",
    "print(\"üí° Final Answer:\\n\", answer)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluate ONLY RETRIEVE Performance"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from src.evaluate_retrieve import run_evaluation\n",
    "\n",
    "run_evaluation(config=config)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from src.evaluate_rag_full import run_full_rag_eval\n",
    "\n",
    "run_full_rag_eval(config=config, max_questions=10000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
