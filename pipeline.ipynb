{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T20:33:45.423051Z",
     "start_time": "2025-11-29T20:33:45.406742Z"
    }
   },
   "source": [
    "from src.config import LocalConfig, ColabConfig, is_colab\n",
    "\n",
    "config = ColabConfig(embedding_model=\"BAAI/bge-base-en\") if is_colab() else LocalConfig()\n",
    "\n",
    "print(\"Using configuration:\", type(config).__name__)\n",
    "print(\"Base directory:\", config.BASE_DIR)\n",
    "\n",
    "config.ensure_dirs()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using configuration: LocalConfig\n",
      "Base directory: /mnt/c/dev/ml/rag-qa\n",
      "‚úÖ Ensured directory exists: /mnt/c/dev/ml/rag-qa/.hf_cache\n",
      "‚úÖ Ensured directory exists: /mnt/c/dev/ml/rag-qa/data\n",
      "‚úÖ Ensured directory exists: /mnt/c/dev/ml/rag-qa/data/train\n",
      "‚úÖ Ensured directory exists: /mnt/c/dev/ml/rag-qa/data/validation\n",
      "‚úÖ Ensured directory exists: /mnt/c/dev/ml/rag-qa/data/test\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T20:33:51.250035Z",
     "start_time": "2025-11-29T20:33:48.793542Z"
    }
   },
   "source": [
    "# Single cell: safe to run on a fresh environment\n",
    "from src.load_data import ensure_data_available\n",
    "\n",
    "# ‚úÖ Creates folders if missing and downloads only if needed\n",
    "ensure_data_available(config=config)\n",
    "\n",
    "print(\"üöÄ Dataset ready\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucas/.virtualenvs/rag-qa/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úî Dataset already downloaded ‚Äî skipping.\n",
      "üöÄ Dataset ready\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T20:34:05.859040Z",
     "start_time": "2025-11-29T20:33:54.287805Z"
    }
   },
   "source": [
    "# Single cell to explore dataset shards\n",
    "from src.explore_data import load_shards, explore_dataset\n",
    "\n",
    "# Load first few shards to save memory\n",
    "train_ds = load_shards(config.TRAIN_DIR, max_shards=3)\n",
    "val_ds   = load_shards(config.VAL_DIR, max_shards=3)\n",
    "test_ds  = load_shards(config.TEST_DIR, max_shards=3)\n",
    "\n",
    "# Explore datasets\n",
    "explore_dataset(train_ds, \"Train set\")\n",
    "explore_dataset(val_ds, \"Validation set\")\n",
    "explore_dataset(test_ds, \"Test set\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exploring Train set:\n",
      "Total examples across all shards: 3000\n",
      "Columns: ['question', 'question_id', 'question_source', 'entity_pages', 'search_results', 'answer']\n",
      "\n",
      "Column types:\n",
      " - question: Value('string')\n",
      " - question_id: Value('string')\n",
      " - question_source: Value('string')\n",
      " - entity_pages: {'doc_source': List(Value('string')), 'filename': List(Value('string')), 'title': List(Value('string')), 'wiki_context': List(Value('string'))}\n",
      " - search_results: {'description': List(Value('null')), 'filename': List(Value('null')), 'rank': List(Value('null')), 'search_context': List(Value('null')), 'title': List(Value('null')), 'url': List(Value('null'))}\n",
      " - answer: {'aliases': List(Value('string')), 'matched_wiki_entity_name': Value('string'), 'normalized_aliases': List(Value('string')), 'normalized_matched_wiki_entity_name': Value('string'), 'normalized_value': Value('string'), 'type': Value('string'), 'value': Value('string')}\n",
      "\n",
      "Sample data from first 3 examples (strings truncated to 50 chars):\n",
      "{'question': 'Which Mediterranean island was once known as Alash...', 'question_id': 'qb_6731', 'question_source': 'http://www.quizballs.com/', 'entity_pages': {'doc_source': ['TagMe', 'TagMe'], 'filename': ['Mediterranean_Sea.txt', 'Alashiya.txt'], 'title': ['Mediterranean Sea', 'Alashiya'], 'wiki_context': ['The\\xa0Mediterranean Sea (pronounced) is a sea  conne...', 'Alashiya, also spelled Alasiya, was a state which ...']}, 'search_results': {'description': [], 'filename': [], 'rank': [], 'search_context': [], 'title': [], 'url': []}, 'answer': {'aliases': ['Culture of Cyprus', 'Kƒ±brƒ±s', 'Etymology of Cyprus', 'History of ancient Cyprus', 'Island of Cyprus', 'Name of Northern Cyprus', 'ISO 3166-1:CY', 'Zypern', 'South Cyprus (Greek Cyprus)', 'Architecture of Cyprus', 'Colony of Cyprus', 'Country CYP', 'Kibris', 'Southern Cyprus', 'Political system of cyprus', 'Greek Cyprus', 'Kypros', 'ŒöœçœÄœÅŒøœÇ', 'Cyrpus', 'Greek Cypriot Administration of Southern Cyprus', 'Republic of Cyprus', 'Ciprus', 'Name of Cyprus', 'ŒöœÖœÄœÅŒπŒ±Œ∫ŒÆ ŒîŒ∑ŒºŒøŒ∫œÅŒ±œÑŒØŒ±', 'Cyprus', 'Cyprus goods', 'Cyprus (Republic of)', 'Greek Republic of Cyprus'], 'matched_wiki_entity_name': '', 'normalized_aliases': ['culture of cyprus', 'kibris', 'political system of cyprus', 'architecture of cyprus', 'south cyprus greek cyprus', 'cyprus', 'kƒ±brƒ±s', 'country cyp', 'greek cyprus', 'cyprus goods', 'greek republic of cyprus', 'greek cypriot administration of southern cyprus', 'cyprus republic of', 'colony of cyprus', 'island of cyprus', 'southern cyprus', 'ciprus', 'name of northern cyprus', 'kypros', 'history of ancient cyprus', 'Œ∫œçœÄœÅŒøœÇ', 'republic of cyprus', 'name of cyprus', 'Œ∫œÖœÄœÅŒπŒ±Œ∫ŒÆ Œ¥Œ∑ŒºŒøŒ∫œÅŒ±œÑŒØŒ±', 'zypern', 'cyrpus', 'etymology of cyprus', 'iso 3166 1 cy'], 'normalized_matched_wiki_entity_name': '', 'normalized_value': 'cyprus', 'type': 'WikipediaEntity', 'value': 'Cyprus'}}\n",
      "{'question': 'What is the top prize at the Cannes Film Festival?', 'question_id': 'qb_6734', 'question_source': 'http://www.quizballs.com/', 'entity_pages': {'doc_source': ['TagMe'], 'filename': ['Cannes_Film_Festival.txt'], 'title': ['Cannes Film Festival'], 'wiki_context': ['The Cannes Festival (French: Festival de Cannes), ...']}, 'search_results': {'description': [], 'filename': [], 'rank': [], 'search_context': [], 'title': [], 'url': []}, 'answer': {'aliases': [\"Palm d'Or\", 'Golden Palm Award', \"The Palme d'Or\", 'Golden palm award', 'The Golden Palm Award', 'Golden Palm Awards', 'Palme d‚ÄôOr', 'Palme d¬¥Or', \"Palme D'or\", \"Palme d'Or\", 'Palm d‚ÄôOr', \"Palme d'or\", \"Palme D'Or\", \"The Palme D'or\", 'Golden Palm'], 'matched_wiki_entity_name': '', 'normalized_aliases': ['golden palm', 'palme d or', 'golden palm awards', 'palm d or', 'golden palm award'], 'normalized_matched_wiki_entity_name': '', 'normalized_value': 'palm d or', 'type': 'WikipediaEntity', 'value': 'Palm d‚ÄôOr'}}\n",
      "{'question': 'The medical condition glaucoma affects which part ...', 'question_id': 'qb_6735', 'question_source': 'http://www.quizballs.com/', 'entity_pages': {'doc_source': ['TagMe', 'TagMe', 'TagMe'], 'filename': ['Disease.txt', 'Glaucoma.txt', 'Human_body.txt'], 'title': ['Disease', 'Glaucoma', 'Human body'], 'wiki_context': ['A disease  is a particular abnormal condition, a d...', 'Glaucoma is a group of eye diseases which result i...', 'The human body is the entire structure of a human ...']}, 'search_results': {'description': [], 'filename': [], 'rank': [], 'search_context': [], 'title': [], 'url': []}, 'answer': {'aliases': ['Eye (anatomy)', 'Eye', 'Eye balls', 'Schizochroal eye', 'Ocular globe', 'Ommateum', 'Simple eye', 'Oculars', 'Animal eyes', 'Eyes', 'Compound Eyes', 'Apposition eye', 'Robotic eye', 'Eye ball', 'Facet eyes', 'Compound Eye', 'Conjunctival disorders', 'Compound eyes', 'Eyeball', 'Cyber-eye', 'Eye (vertebrate)', 'Eye (invertebrate)', 'Ommotidium', \"Fly's eye lens\", 'Peeper (organ)', 'Camera-type eye', 'Ocular', 'Compound eye', 'Eye membrane', 'Pinhole eye'], 'matched_wiki_entity_name': '', 'normalized_aliases': ['compound eyes', 'oculars', 'facet eyes', 'cyber eye', 'ommateum', 'peeper organ', 'eye balls', 'compound eye', 'simple eye', 'eye vertebrate', 'animal eyes', 'camera type eye', 'eye membrane', 'apposition eye', 'eyeball', 'eye', 'ommotidium', 'eyes', 'robotic eye', 'ocular globe', 'eye anatomy', 'pinhole eye', 'eye ball', 'conjunctival disorders', 'fly s eye lens', 'ocular', 'schizochroal eye', 'eye invertebrate'], 'normalized_matched_wiki_entity_name': '', 'normalized_value': 'eye', 'type': 'WikipediaEntity', 'value': 'Eye'}}\n",
      "\n",
      "Basic text statistics (lengths in words) for columns:\n",
      "Column 'question': mean=13.22, min=5, max=46\n",
      "Column 'question_id': mean=1.00, min=1, max=1\n",
      "Column 'question_source': mean=1.00, min=1, max=1\n",
      "\n",
      "Top 10 most common labels in 'answer':\n",
      "[('canada', 14), ('fish', 11), ('australia', 11), ('four', 10), ('red', 10), ('india', 10), ('france', 9), ('three', 9), ('two', 9), ('blue', 9)]\n",
      "\n",
      "Exploring Validation set:\n",
      "Total examples across all shards: 3000\n",
      "Columns: ['question', 'question_id', 'question_source', 'entity_pages', 'search_results', 'answer']\n",
      "\n",
      "Column types:\n",
      " - question: Value('string')\n",
      " - question_id: Value('string')\n",
      " - question_source: Value('string')\n",
      " - entity_pages: {'doc_source': List(Value('string')), 'filename': List(Value('string')), 'title': List(Value('string')), 'wiki_context': List(Value('string'))}\n",
      " - search_results: {'description': List(Value('null')), 'filename': List(Value('null')), 'rank': List(Value('null')), 'search_context': List(Value('null')), 'title': List(Value('null')), 'url': List(Value('null'))}\n",
      " - answer: {'aliases': List(Value('string')), 'matched_wiki_entity_name': Value('string'), 'normalized_aliases': List(Value('string')), 'normalized_matched_wiki_entity_name': Value('string'), 'normalized_value': Value('string'), 'type': Value('string'), 'value': Value('string')}\n",
      "\n",
      "Sample data from first 3 examples (strings truncated to 50 chars):\n",
      "{'question': 'Where in England was Dame Judi Dench born?', 'question_id': 'tc_3', 'question_source': 'http://www.triviacountry.com/', 'entity_pages': {'doc_source': ['TagMe', 'TagMe'], 'filename': ['England.txt', 'Judi_Dench.txt'], 'title': ['England', 'Judi Dench'], 'wiki_context': ['England is a country that is part of the United Ki...', 'Dame Judith Olivia \"Judi\" Dench,  (born 9 December...']}, 'search_results': {'description': [], 'filename': [], 'rank': [], 'search_context': [], 'title': [], 'url': []}, 'answer': {'aliases': ['Park Grove (1895)', 'York UA', 'Yorkish', 'UN/LOCODE:GBYRK', 'York, UK', 'Eoforwic', 'Park Grove School', 'York Ham', 'The weather in York', 'City of York', 'York, England', 'York, Yorkshire', 'York ham', 'County Borough of York', 'YORK', 'Eoferwic', 'Park Grove Primary School', 'York, North Yorkshire', 'Yoisk', 'York', 'York (England)'], 'matched_wiki_entity_name': '', 'normalized_aliases': ['york yorkshire', 'eoferwic', 'park grove primary school', 'park grove school', 'weather in york', 'park grove 1895', 'eoforwic', 'county borough of york', 'york uk', 'un locode gbyrk', 'city of york', 'york england', 'york ua', 'york ham', 'york', 'yorkish', 'yoisk', 'york north yorkshire'], 'normalized_matched_wiki_entity_name': '', 'normalized_value': 'york', 'type': 'WikipediaEntity', 'value': 'York'}}\n",
      "{'question': 'From which country did Angola achieve independence...', 'question_id': 'tc_8', 'question_source': 'http://www.triviacountry.com/', 'entity_pages': {'doc_source': ['TagMe', 'TagMe', 'Search'], 'filename': ['Nation_state.txt', 'Angola.txt', 'Angolan_Civil_War.txt'], 'title': ['Nation state', 'Angola', 'Angolan Civil War'], 'wiki_context': ['A nation state is a type of state that conjoins th...', 'Angola, officially the Republic of Angola (; Kikon...', 'The Angolan Civil War () was a major civil conflic...']}, 'search_results': {'description': [], 'filename': [], 'rank': [], 'search_context': [], 'title': [], 'url': []}, 'answer': {'aliases': ['Portoga≈Ço', 'Republic of Portugal', 'PORTUGAL', 'Portekiz', 'Portugallu', 'O Papagaio', 'ISO 3166-1:PT', 'Portunga', 'Phu-to-ga', 'Potigal', 'Port√ªnga', 'Portugul', 'An Phortaing√©il', 'PortugƒÅle', 'Portugale', 'Portingale', 'Potiti', 'Portugali', 'Portugall', 'Portek√Æz', 'Bo Dao Nha', 'Portuguese Republic', 'Portogallo', 'Portugaul', 'Portogalo', 'Portyngal', 'Yn Phortiugal', 'Portugalio', 'Portug√°l', 'Portugual', 'Portuga', 'Portgual', 'Portugalsko', 'Portugaleje', 'Ph√ª-t√¥-g√¢', 'Portugalujo', 'Portugalija', 'Pertual', 'P√≤tigal', 'Portugal', 'B·ªì ƒê√†o Nha', 'Portugalska', 'Rep√∫blica Portuguesa', 'Portiwgal', 'Portugalƒójƒó', 'Port√∫gal', 'Portegal', 'An Phortaingeil', 'Republica Portuguesa'], 'matched_wiki_entity_name': '', 'normalized_aliases': ['portugul', 'portugallu', 'portugalska', 'p√≤tigal', 'portugaul', 'portugalujo', 'portuguese republic', 'iso 3166 1 pt', 'republic of portugal', 'portugalsko', 'portugual', 'b·ªì ƒë√†o nha', 'portugall', 'port√ªnga', 'bo dao nha', 'phortaingeil', 'portugale', 'portugal', 'portug√°l', 'portugalƒójƒó', 'portiwgal', 'phu to ga', 'portugalija', 'portugalio', 'portogallo', 'ph√ª t√¥ g√¢', 'portegal', 'rep√∫blica portuguesa', 'portugƒÅle', 'phortaing√©il', 'yn phortiugal', 'portoga≈Ço', 'portuga', 'portugaleje', 'portekiz', 'o papagaio', 'portunga', 'potigal', 'portek√Æz', 'pertual', 'portogalo', 'portugali', 'portyngal', 'republica portuguesa', 'portingale', 'port√∫gal', 'portgual', 'potiti'], 'normalized_matched_wiki_entity_name': '', 'normalized_value': 'portugal', 'type': 'WikipediaEntity', 'value': 'Portugal'}}\n",
      "{'question': 'Which city does David Soul come from?', 'question_id': 'tc_9', 'question_source': 'http://www.triviacountry.com/', 'entity_pages': {'doc_source': ['TagMe'], 'filename': ['David_Soul.txt'], 'title': ['David Soul'], 'wiki_context': ['David Soul (born August 28, 1943) is an American-B...']}, 'search_results': {'description': [], 'filename': [], 'rank': [], 'search_context': [], 'title': [], 'url': []}, 'answer': {'aliases': ['Chi-Beria', 'Sayre language academy', 'Chicago', 'Chicago, Illinois', 'Hog Butcher for the World', 'Land of smelly onions', 'Ariel Community Academy', 'The weather in Chicago', 'Chicago, Illinois, U.S.A.', 'Chicago, Illionis', 'Near North Montessori', 'Religion in Chicago', 'Chicago Finance Committee', 'The Paris of America', 'The city of Chicago', 'City of Chicago', 'List of sister cities of Chicago', 'UN/LOCODE:USCHI', 'Chicago theatre scene', 'Chicago, WI', 'The City of Broad Shoulders', 'City of Broad Shoulders', 'Sister Cities of Chicago', 'Chicago il', 'Chicago, Illinois, USA', 'Performing arts in Chicago', 'Chicago Transportation Committee', 'Chicago, Wisconsin', 'City of chicago', 'Chicago theater scene', 'Chicago, Il', 'Chicago, IL.', 'Chicago, Ill.', 'City of Chicago, Illinois', 'Chi town', 'Chicago, United States', 'Chicago (Ill.)', 'Transport in Chicago', 'Chicago, Illinois, United States', 'Chicago (IL)', 'USCHI', 'Chichago', 'Chcago', 'Chicago, Illinois, U.S.', 'Sister Cities Chicago', 'Chicago, USA', 'Chi City', 'Chicago, IL', 'Chi-Town', 'Chicago theatre', 'Paris of America', 'Chicago, Illinois, US', 'Chicago Illinois', 'The city of Chicago, Illinois', 'Sister cities of Chicago'], 'matched_wiki_entity_name': '', 'normalized_aliases': ['sayre language academy', 'chicago transportation committee', 'chicago illinois u s', 'sister cities of chicago', 'sister cities chicago', 'transport in chicago', 'chicago illinois', 'chicago illinois usa', 'chi town', 'hog butcher for world', 'religion in chicago', 'chicago', 'chicago wi', 'near north montessori', 'un locode uschi', 'city of broad shoulders', 'chicago theatre', 'chicago usa', 'uschi', 'chicago il', 'city of chicago', 'chicago finance committee', 'list of sister cities of chicago', 'chi beria', 'weather in chicago', 'chicago wisconsin', 'land of smelly onions', 'ariel community academy', 'chicago theater scene', 'chicago united states', 'paris of america', 'chicago illionis', 'chicago illinois united states', 'chcago', 'chi city', 'chicago illinois us', 'performing arts in chicago', 'chicago theatre scene', 'chichago', 'chicago ill', 'city of chicago illinois'], 'normalized_matched_wiki_entity_name': '', 'normalized_value': 'chicago', 'type': 'WikipediaEntity', 'value': 'Chicago'}}\n",
      "\n",
      "Basic text statistics (lengths in words) for columns:\n",
      "Column 'question': mean=11.86, min=5, max=43\n",
      "Column 'question_id': mean=1.00, min=1, max=1\n",
      "Column 'question_source': mean=1.00, min=1, max=1\n",
      "\n",
      "Top 10 most common labels in 'answer':\n",
      "[('three', 8), ('ireland', 8), ('spain', 8), ('portugal', 7), ('norway', 6), ('italy', 6), ('6', 6), ('two', 6), ('chicago', 5), ('switzerland', 5)]\n",
      "\n",
      "Exploring Test set:\n",
      "Total examples across all shards: 3000\n",
      "Columns: ['question', 'question_id', 'question_source', 'entity_pages', 'search_results', 'answer']\n",
      "\n",
      "Column types:\n",
      " - question: Value('string')\n",
      " - question_id: Value('string')\n",
      " - question_source: Value('string')\n",
      " - entity_pages: {'doc_source': List(Value('string')), 'filename': List(Value('string')), 'title': List(Value('string')), 'wiki_context': List(Value('string'))}\n",
      " - search_results: {'description': List(Value('null')), 'filename': List(Value('null')), 'rank': List(Value('null')), 'search_context': List(Value('null')), 'title': List(Value('null')), 'url': List(Value('null'))}\n",
      " - answer: {'aliases': List(Value('string')), 'matched_wiki_entity_name': Value('string'), 'normalized_aliases': List(Value('string')), 'normalized_matched_wiki_entity_name': Value('string'), 'normalized_value': Value('string'), 'type': Value('string'), 'value': Value('string')}\n",
      "\n",
      "Sample data from first 3 examples (strings truncated to 50 chars):\n",
      "{'question': 'Which Lloyd Webber musical premiered in the US on ...', 'question_id': 'tc_33', 'question_source': 'http://www.triviacountry.com/', 'entity_pages': {'doc_source': ['TagMe'], 'filename': ['Andrew_Lloyd_Webber.txt'], 'title': ['Andrew Lloyd Webber'], 'wiki_context': ['Andrew Lloyd Webber, Baron Lloyd-Webber   (born 22...']}, 'search_results': {'description': [], 'filename': [], 'rank': [], 'search_context': [], 'title': [], 'url': []}, 'answer': {'aliases': ['Sunset Blvd', 'West Sunset Boulevard', 'Sunset Boulevard', 'Sunset Bulevard', 'Sunset Blvd.'], 'matched_wiki_entity_name': '', 'normalized_aliases': ['sunset boulevard', 'sunset bulevard', 'west sunset boulevard', 'sunset blvd'], 'normalized_matched_wiki_entity_name': '', 'normalized_value': 'sunset boulevard', 'type': 'WikipediaEntity', 'value': 'Sunset Boulevard'}}\n",
      "{'question': 'Who was the next British Prime Minister after Arth...', 'question_id': 'tc_40', 'question_source': 'http://www.triviacountry.com/', 'entity_pages': {'doc_source': ['TagMe', 'TagMe'], 'filename': ['Prime_Minister_of_the_United_Kingdom.txt', 'Arthur_Balfour.txt'], 'title': ['Prime Minister of the United Kingdom', 'Arthur Balfour'], 'wiki_context': ['The Prime Minister of the United Kingdom of Great ...', 'Arthur James Balfour, 1st Earl of Balfour,  (;  25...']}, 'search_results': {'description': [], 'filename': [], 'rank': [], 'search_context': [], 'title': [], 'url': []}, 'answer': {'aliases': ['Sir Henry Campbell-Bannerman', 'Campbell-Bannerman', 'Campbell Bannerman', 'Sir Henry Campbell Bannerman', 'Henry Campbell Bannerman', 'Henry Campbell-Bannerman'], 'matched_wiki_entity_name': '', 'normalized_aliases': ['henry campbell bannerman', 'sir henry campbell bannerman', 'campbell bannerman'], 'normalized_matched_wiki_entity_name': '', 'normalized_value': 'campbell bannerman', 'type': 'WikipediaEntity', 'value': 'Campbell-Bannerman'}}\n",
      "{'question': 'Who had a 70s No 1 hit with Kiss You All Over?', 'question_id': 'tc_49', 'question_source': 'http://www.triviacountry.com/', 'entity_pages': {'doc_source': ['TagMe'], 'filename': ['Kiss_You_All_Over.txt'], 'title': ['Kiss You All Over'], 'wiki_context': ['\"Kiss You All Over\" is a 1978 song performed by th...']}, 'search_results': {'description': [], 'filename': [], 'rank': [], 'search_context': [], 'title': [], 'url': []}, 'answer': {'aliases': ['Internal exile', 'Exiles', 'Transported for life', 'Exile (politics and government)', 'Voluntary exile', 'Sent into exile', 'Exile and Banishment', 'Self-exile', 'Forced exile', 'Exile', 'Exile in Greek tragedy', 'Banish', 'Banishment'], 'matched_wiki_entity_name': '', 'normalized_aliases': ['exiles', 'voluntary exile', 'forced exile', 'banish', 'self exile', 'exile politics and government', 'exile in greek tragedy', 'sent into exile', 'banishment', 'transported for life', 'exile', 'internal exile', 'exile and banishment'], 'normalized_matched_wiki_entity_name': '', 'normalized_value': 'exile', 'type': 'WikipediaEntity', 'value': 'Exile'}}\n",
      "\n",
      "Basic text statistics (lengths in words) for columns:\n",
      "Column 'question': mean=13.32, min=5, max=55\n",
      "Column 'question_id': mean=1.00, min=1, max=1\n",
      "Column 'question_source': mean=1.00, min=1, max=1\n",
      "\n",
      "Top 10 most common labels in 'answer':\n",
      "[('france', 12), ('argentina', 9), ('three', 8), ('red', 8), ('australia', 8), ('spain', 8), ('new zealand', 7), ('switzerland', 7), ('scotland', 7), ('blue', 7)]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T19:43:25.343564Z",
     "start_time": "2025-11-29T19:43:23.970041Z"
    }
   },
   "source": [
    "from src.analyze_data import load_shards_concat, dataset_info, analyze_lengths, most_common_answers, print_sample_qa\n",
    "\n",
    "# Load datasets\n",
    "train_ds = load_shards_concat(config.TRAIN_DIR)\n",
    "val_ds   = load_shards_concat(config.VAL_DIR)\n",
    "test_ds  = load_shards_concat(config.TEST_DIR)\n",
    "\n",
    "# Explore datasets and save plots in the 'plots/' folder\n",
    "# for name, ds in [(\"Train\", train_ds), (\"Validation\", val_ds), (\"Test\", test_ds)]:\n",
    "#     if ds is None:\n",
    "#         print(f\"No dataset found for {name}\")\n",
    "#         continue\n",
    "#     dataset_info(ds, name)\n",
    "#     analyze_lengths(ds, \"question\", name)\n",
    "#     analyze_lengths(ds, \"answer\", name)\n",
    "#     most_common_answers(ds)\n",
    "#     print_sample_qa(ds, name, n=5)\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T20:56:43.132536Z",
     "start_time": "2025-11-29T20:34:14.356174Z"
    }
   },
   "source": [
    "from src.compute_embeddings import compute_embeddings, retrieve_top_k\n",
    "\n",
    "# Compute embeddings (will load from file if already exists)\n",
    "corpus, corpus_embeddings = compute_embeddings(config=config)\n",
    "\n",
    "# Test retrieval\n",
    "query = \"What is the capital of france?\"\n",
    "results, scores = retrieve_top_k(query=query, corpus=corpus, corpus_embeddings=corpus_embeddings, config=config, top_k=3)\n",
    "\n",
    "print(\"\\nTop 3 retrieved passages for query:\")\n",
    "for passage, score in zip(results, scores):\n",
    "    print(f\"[score: {score:.4f}] {passage}\\n---\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings not found or force_recompute=True, computing embeddings...\n",
      "Reused cached passages from /mnt/c/dev/ml/rag-qa/corpus_passages.pkl (978526 passages).\n",
      "Using model: SentenceTransformer\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1912/1912 [21:56<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved embeddings to /mnt/c/dev/ml/rag-qa/corpus_embeddings_unique.pkl\n",
      "Saved FAISS index to /mnt/c/dev/ml/rag-qa/corpus_faiss.index (dim=384, n=978526)\n",
      "\n",
      "Top 3 retrieved passages for query:\n",
      "[score: 0.6164] Geography of France: france is a country in western europe. france borders the atlantic ocean and the mediterranean. to the west is the bay of biscay, to the north is the english channel and the north sea. france also has territory in south america, the caribbean, and the indian ocean, as well as numerous territories of various status. area * total area : 673, 801 km * * ( whole territory of the french republic, including all the overseas departments and territories, but excluding the disputed french territory of terre adelie in antarctica ) * metropolitan france : 551, 695 km * * ( metropolitan - i. e. european - france only, french national geographic institute data ) * metropolitan france : 543, 965 km * * ( metropolitan - i. e. european - france only, french land register data, which exclude lakes, ponds, glaciers larger than 1 km, and estuaries ) terrain mostly flat plains or gently rolling hills in north and west. the remainder is mountainous, especially pyrenees in south, alps in east. elevation extremes : * lowest point : rhone river delta - 2 m * highest point : mont blanc 4, 808 m land use * arable land\n",
      "---\n",
      "[score: 0.6148] France: france ( french : ), officially the french republic ( ), is a sovereign state comprising territory in western europe and several overseas regions and territories. the european, or metropolitan, area of france extends from the mediterranean sea to the english channel and the north sea, and from the rhine to the atlantic ocean. france spans 643801 km2 and has a total population of 66. 7 million. it is a unitary semi - presidential republic with the capital in paris, the country ' s largest city and main cultural and commercial centre. during the iron age, what is now metropolitan france was inhabited by the gauls, a celtic people. the area was annexed in 51 bc by rome, which held gaul until 486, when the germanic franks conquered the region and formed the kingdom of france. france emerged as a major european power in the late middle ages, with its victory in the hundred years ' war ( 1337 to 1453 ) strengthening state - building and political centralization. during the renaissance, french culture flourished and a global colonial empire was established, which by the 20th century would be the second largest in the world. the 16th century was dominated by religious civil wars between catholics and protestants ( hug\n",
      "---\n",
      "[score: 0.6138] Geography of France: land and is administered by the high - commissioner of the french republic in french polynesia : clipperton. boundaries * land boundaries : * * total : * * 2751 km ( metropolitan ), 1205 km ( french guiana ) ( saint martin ) * border countries : * * andorra 55 km, belgium 556 km, germany 418 km, italy 476 km, luxembourg 69 km, monaco 6 km, spain 646 km, switzerland 525 km ( metropolitan ) * * brazil 649 km, suriname 556 km, 1183 km ( french guiana ) * * sint maarten ( saint martin ) * coastline : ( metropolitan ), 378 km ( french guiana ), 306 km ( guadeloupe ), 350 km ( martinique ), 207 km ( reunion ) * maritime claims : * * territorial sea : 12 nmi * * contiguous zone : 24 nmi * * exclusive economic zone : 200 nmi ; does not apply to the mediterranean * * continental shelf : 200 m depth or to the depth of exploitation extreme points this is a list of the extreme points of france ; the points that are farther north, south, east or west than any other location. france (\n",
      "---\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Loaded 100 passages from corpus_embeddings_unique.pkl\n",
      "üîπ Loading FLAN-T5 model...\n",
      "üîπ Loading embedding model...\n",
      "\n",
      "üîç Used Context Passages:\n",
      "\n",
      "1. Mediterranean Sea: the city of Haifa, Israel File:Gaza Beach.jpg|Beach on the Gaza Strip, State of Palestine File:Coast of Alexandria, A view From Bibliotheca Alexandrina, Egypt.jpg|Coast of Alexandri...\n",
      "\n",
      "2. Mediterranean Sea: of Cape Trafalgar (Spain) and Cape Spartel (Africa). **On the northeast: The west coast of Italy. In the Strait of Messina a line joining the north extreme of Cape Paci (15¬∞42'E) wi...\n",
      "\n",
      "3. Mediterranean Sea: as well as food (from fishing and the gathering of other seafood) for numerous communities throughout the ages. Due to the shared climate, geology, and access to the sea, cultures c...\n",
      "\n",
      "4. Cannes Film Festival: last section of the Official Selection: la Cin√©fondation. Its aim was to support the creation of works of cinema in the world and to contribute to the entry of the new scenario w...\n",
      "\n",
      "5. Mediterranean Sea: Egypt. *Island nations: Malta, Cyprus. Several other territories also border the Mediterranean Sea (from west to east): The British overseas territory of Gibraltar, the Spanish auto...\n",
      "\n",
      "üí° Final Answer:\n",
      " Oceanography Being nearly landlocked affects conditions in the Mediterranean Sea: for instance, tides are very limited\n"
     ]
    }
   ],
   "source": [
    "from src.generator import load_embeddings, generate_answer_combined\n",
    "\n",
    "corpus, emb = load_embeddings()\n",
    "\n",
    "query = \"What is the capital of france?\"\n",
    "answer, ctx = generate_answer_combined(query, corpus, emb, top_k=5)\n",
    "\n",
    "print(\"\\nüîç Used Context Passages:\\n\")\n",
    "for i,p in enumerate(ctx,1):\n",
    "    print(f\"{i}. {p[:200].replace(chr(10),' ')}...\\n\")\n",
    "\n",
    "print(\"üí° Final Answer:\\n\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate ONLY RETRIEVE Performance"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T20:59:42.990823Z",
     "start_time": "2025-11-29T20:57:14.766275Z"
    }
   },
   "source": [
    "from src.evaluate_retrieve import run_evaluation\n",
    "\n",
    "run_evaluation(config=config)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Loaded FAISS index with 978526 passages\n",
      "\n",
      "=== üî• Evaluating TRAIN ‚Äî first 1000 samples ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading /mnt/c/dev/ml/rag-qa/data/train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 54/54 [00:00<00:00, 61.66it/s]\n",
      "Evaluating Recall: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:44<00:00, 22.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@1: 0.6310\n",
      "Recall@3: 0.8350\n",
      "Recall@5: 0.8930\n",
      "Recall@7: 0.9140\n",
      "Recall@10: 0.9290\n",
      "\n",
      "=== üî• Evaluating VALIDATION ‚Äî first 1000 samples ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading /mnt/c/dev/ml/rag-qa/data/validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:00<00:00, 75.20it/s]\n",
      "Evaluating Recall: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:44<00:00, 22.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@1: 0.5240\n",
      "Recall@3: 0.7410\n",
      "Recall@5: 0.7890\n",
      "Recall@7: 0.8180\n",
      "Recall@10: 0.8440\n",
      "\n",
      "=== üî• Evaluating TEST ‚Äî first 1000 samples ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading /mnt/c/dev/ml/rag-qa/data/test: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:00<00:00, 73.01it/s]\n",
      "Evaluating Recall: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:44<00:00, 22.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@1: 0.6280\n",
      "Recall@3: 0.8030\n",
      "Recall@5: 0.8480\n",
      "Recall@7: 0.8700\n",
      "Recall@10: 0.8940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Loading embeddings ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Loading Test dataset (100 samples) ===\n",
      "\n",
      "=== Running RAG Evaluation ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (3761 > 512). Running this sequence through the model will result in indexing errors\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 864.00 MiB. GPU 0 has a total capacity of 7.58 GiB of which 854.50 MiB is free. Including non-PyTorch memory, this process has 6.71 GiB memory in use. Of the allocated memory 6.54 GiB is allocated by PyTorch, and 32.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mOutOfMemoryError\u001B[39m                          Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msrc\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mevaluate_rag_full\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m run_full_rag_eval\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m \u001B[43mrun_full_rag_eval\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/proj/ciptmp/du69limo/to/rag-qa/src/evaluate_rag_full.py:109\u001B[39m, in \u001B[36mrun_full_rag_eval\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m    106\u001B[39m aliases = ex[\u001B[33m\"\u001B[39m\u001B[33manswer\u001B[39m\u001B[33m\"\u001B[39m][\u001B[33m\"\u001B[39m\u001B[33mnormalized_aliases\u001B[39m\u001B[33m\"\u001B[39m] + [gold]\n\u001B[32m    108\u001B[39m retrieved = retrieve(q, embed_model, corpus, corpus_emb, k=TOP_K)\n\u001B[32m--> \u001B[39m\u001B[32m109\u001B[39m pred = \u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretrieved\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgen_model\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    111\u001B[39m em_results.append(exact_match(pred, gold))\n\u001B[32m    112\u001B[39m contains_results.append(contains_match(pred, aliases))\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/proj/ciptmp/du69limo/to/rag-qa/src/evaluate_rag_full.py:68\u001B[39m, in \u001B[36mgenerate\u001B[39m\u001B[34m(query, retrieved, tokenizer, model)\u001B[39m\n\u001B[32m     66\u001B[39m inputs = tokenizer(prompt, return_tensors=\u001B[33m\"\u001B[39m\u001B[33mpt\u001B[39m\u001B[33m\"\u001B[39m).to(DEVICE)\n\u001B[32m     67\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m torch.no_grad():\n\u001B[32m---> \u001B[39m\u001B[32m68\u001B[39m     output = \u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_new_tokens\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m128\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     70\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m tokenizer.decode(output[\u001B[32m0\u001B[39m], skip_special_tokens=\u001B[38;5;28;01mTrue\u001B[39;00m).strip()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/proj/ciptmp/du69limo/to/rag-qa/.venv/lib/python3.13/site-packages/torch/utils/_contextlib.py:120\u001B[39m, in \u001B[36mcontext_decorator.<locals>.decorate_context\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    117\u001B[39m \u001B[38;5;129m@functools\u001B[39m.wraps(func)\n\u001B[32m    118\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mdecorate_context\u001B[39m(*args, **kwargs):\n\u001B[32m    119\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[32m--> \u001B[39m\u001B[32m120\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/proj/ciptmp/du69limo/to/rag-qa/.venv/lib/python3.13/site-packages/transformers/generation/utils.py:2465\u001B[39m, in \u001B[36mGenerationMixin.generate\u001B[39m\u001B[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001B[39m\n\u001B[32m   2461\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33m`attention_mask` passed to `generate` must be 2D.\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m   2463\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.config.is_encoder_decoder \u001B[38;5;129;01mand\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mencoder_outputs\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m model_kwargs:\n\u001B[32m   2464\u001B[39m     \u001B[38;5;66;03m# if model is encoder decoder encoder_outputs are created and added to `model_kwargs`\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m2465\u001B[39m     model_kwargs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_prepare_encoder_decoder_kwargs_for_generation\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2466\u001B[39m \u001B[43m        \u001B[49m\u001B[43minputs_tensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_input_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgeneration_config\u001B[49m\n\u001B[32m   2467\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2469\u001B[39m \u001B[38;5;66;03m# 5. Prepare `input_ids` which will be used for auto-regressive generation\u001B[39;00m\n\u001B[32m   2470\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.config.is_encoder_decoder:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/proj/ciptmp/du69limo/to/rag-qa/.venv/lib/python3.13/site-packages/transformers/generation/utils.py:861\u001B[39m, in \u001B[36mGenerationMixin._prepare_encoder_decoder_kwargs_for_generation\u001B[39m\u001B[34m(self, inputs_tensor, model_kwargs, model_input_name, generation_config)\u001B[39m\n\u001B[32m    859\u001B[39m encoder_kwargs[\u001B[33m\"\u001B[39m\u001B[33mreturn_dict\u001B[39m\u001B[33m\"\u001B[39m] = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m    860\u001B[39m encoder_kwargs[model_input_name] = inputs_tensor\n\u001B[32m--> \u001B[39m\u001B[32m861\u001B[39m model_kwargs[\u001B[33m\"\u001B[39m\u001B[33mencoder_outputs\u001B[39m\u001B[33m\"\u001B[39m]: ModelOutput = \u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mencoder_kwargs\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[32m    863\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m model_kwargs\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/proj/ciptmp/du69limo/to/rag-qa/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1774\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1775\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/proj/ciptmp/du69limo/to/rag-qa/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1781\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1782\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1783\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1784\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1785\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1786\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1788\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1789\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/proj/ciptmp/du69limo/to/rag-qa/.venv/lib/python3.13/site-packages/transformers/models/t5/modeling_t5.py:1100\u001B[39m, in \u001B[36mT5Stack.forward\u001B[39m\u001B[34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001B[39m\n\u001B[32m   1097\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m output_hidden_states:\n\u001B[32m   1098\u001B[39m     all_hidden_states = all_hidden_states + (hidden_states,)\n\u001B[32m-> \u001B[39m\u001B[32m1100\u001B[39m layer_outputs = \u001B[43mlayer_module\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1101\u001B[39m \u001B[43m    \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1102\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcausal_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1103\u001B[39m \u001B[43m    \u001B[49m\u001B[43mposition_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1104\u001B[39m \u001B[43m    \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1105\u001B[39m \u001B[43m    \u001B[49m\u001B[43mencoder_extended_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1106\u001B[39m \u001B[43m    \u001B[49m\u001B[43mencoder_decoder_position_bias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# as a positional argument for gradient checkpointing\u001B[39;49;00m\n\u001B[32m   1107\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1108\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcross_attn_layer_head_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcross_attn_layer_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1109\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1110\u001B[39m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[43m=\u001B[49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1111\u001B[39m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1112\u001B[39m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1113\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcache_position\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcache_position\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1114\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1116\u001B[39m hidden_states = layer_outputs[\u001B[32m0\u001B[39m]\n\u001B[32m   1118\u001B[39m \u001B[38;5;66;03m# We share the position biases between the layers - the first layer store them\u001B[39;00m\n\u001B[32m   1119\u001B[39m \u001B[38;5;66;03m# layer_outputs = hidden-states, key-value-states (self-attention position bias), (self-attention weights),\u001B[39;00m\n\u001B[32m   1120\u001B[39m \u001B[38;5;66;03m# (cross-attention position bias), (cross-attention weights)\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/proj/ciptmp/du69limo/to/rag-qa/.venv/lib/python3.13/site-packages/transformers/modeling_layers.py:94\u001B[39m, in \u001B[36mGradientCheckpointingLayer.__call__\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m     91\u001B[39m         logger.warning_once(message)\n\u001B[32m     93\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._gradient_checkpointing_func(partial(\u001B[38;5;28msuper\u001B[39m().\u001B[34m__call__\u001B[39m, **kwargs), *args)\n\u001B[32m---> \u001B[39m\u001B[32m94\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/proj/ciptmp/du69limo/to/rag-qa/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1774\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1775\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/proj/ciptmp/du69limo/to/rag-qa/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1781\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1782\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1783\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1784\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1785\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1786\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1788\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1789\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/proj/ciptmp/du69limo/to/rag-qa/.venv/lib/python3.13/site-packages/transformers/utils/deprecation.py:172\u001B[39m, in \u001B[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    168\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m minimum_action \u001B[38;5;129;01min\u001B[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torchdynamo_compiling():\n\u001B[32m    169\u001B[39m     \u001B[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001B[39;00m\n\u001B[32m    170\u001B[39m     warnings.warn(message, \u001B[38;5;167;01mFutureWarning\u001B[39;00m, stacklevel=\u001B[32m2\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m172\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/proj/ciptmp/du69limo/to/rag-qa/.venv/lib/python3.13/site-packages/transformers/models/t5/modeling_t5.py:687\u001B[39m, in \u001B[36mT5Block.forward\u001B[39m\u001B[34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_values, use_cache, output_attentions, return_dict, cache_position)\u001B[39m\n\u001B[32m    670\u001B[39m \u001B[38;5;129m@deprecate_kwarg\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mpast_key_value\u001B[39m\u001B[33m\"\u001B[39m, new_name=\u001B[33m\"\u001B[39m\u001B[33mpast_key_values\u001B[39m\u001B[33m\"\u001B[39m, version=\u001B[33m\"\u001B[39m\u001B[33m4.58\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    671\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\n\u001B[32m    672\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    685\u001B[39m     cache_position=\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m    686\u001B[39m ):\n\u001B[32m--> \u001B[39m\u001B[32m687\u001B[39m     self_attention_outputs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mlayer\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    688\u001B[39m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    689\u001B[39m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    690\u001B[39m \u001B[43m        \u001B[49m\u001B[43mposition_bias\u001B[49m\u001B[43m=\u001B[49m\u001B[43mposition_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    691\u001B[39m \u001B[43m        \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    692\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    693\u001B[39m \u001B[43m        \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[43m=\u001B[49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    694\u001B[39m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    695\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcache_position\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcache_position\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    696\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    697\u001B[39m     hidden_states = self_attention_outputs[\u001B[32m0\u001B[39m]\n\u001B[32m    698\u001B[39m     attention_outputs = self_attention_outputs[\u001B[32m1\u001B[39m:]  \u001B[38;5;66;03m# Keep self-attention outputs and relative position weights\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/proj/ciptmp/du69limo/to/rag-qa/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1774\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1775\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/proj/ciptmp/du69limo/to/rag-qa/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1781\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1782\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1783\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1784\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1785\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1786\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1788\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1789\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/proj/ciptmp/du69limo/to/rag-qa/.venv/lib/python3.13/site-packages/transformers/utils/deprecation.py:172\u001B[39m, in \u001B[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    168\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m minimum_action \u001B[38;5;129;01min\u001B[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torchdynamo_compiling():\n\u001B[32m    169\u001B[39m     \u001B[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001B[39;00m\n\u001B[32m    170\u001B[39m     warnings.warn(message, \u001B[38;5;167;01mFutureWarning\u001B[39;00m, stacklevel=\u001B[32m2\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m172\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/proj/ciptmp/du69limo/to/rag-qa/.venv/lib/python3.13/site-packages/transformers/models/t5/modeling_t5.py:603\u001B[39m, in \u001B[36mT5LayerSelfAttention.forward\u001B[39m\u001B[34m(self, hidden_states, attention_mask, position_bias, layer_head_mask, past_key_values, use_cache, output_attentions, cache_position)\u001B[39m\n\u001B[32m    590\u001B[39m \u001B[38;5;129m@deprecate_kwarg\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mpast_key_value\u001B[39m\u001B[33m\"\u001B[39m, new_name=\u001B[33m\"\u001B[39m\u001B[33mpast_key_values\u001B[39m\u001B[33m\"\u001B[39m, version=\u001B[33m\"\u001B[39m\u001B[33m4.58\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    591\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\n\u001B[32m    592\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    600\u001B[39m     cache_position=\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m    601\u001B[39m ):\n\u001B[32m    602\u001B[39m     normed_hidden_states = \u001B[38;5;28mself\u001B[39m.layer_norm(hidden_states)\n\u001B[32m--> \u001B[39m\u001B[32m603\u001B[39m     attention_output = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mSelfAttention\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    604\u001B[39m \u001B[43m        \u001B[49m\u001B[43mnormed_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    605\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    606\u001B[39m \u001B[43m        \u001B[49m\u001B[43mposition_bias\u001B[49m\u001B[43m=\u001B[49m\u001B[43mposition_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    607\u001B[39m \u001B[43m        \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    608\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    609\u001B[39m \u001B[43m        \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[43m=\u001B[49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    610\u001B[39m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    611\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcache_position\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcache_position\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    612\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    613\u001B[39m     hidden_states = hidden_states + \u001B[38;5;28mself\u001B[39m.dropout(attention_output[\u001B[32m0\u001B[39m])\n\u001B[32m    614\u001B[39m     outputs = (hidden_states,) + attention_output[\u001B[32m1\u001B[39m:]  \u001B[38;5;66;03m# add attentions if we output them\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/proj/ciptmp/du69limo/to/rag-qa/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1774\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1775\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/proj/ciptmp/du69limo/to/rag-qa/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1781\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1782\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1783\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1784\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1785\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1786\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1788\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1789\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/proj/ciptmp/du69limo/to/rag-qa/.venv/lib/python3.13/site-packages/transformers/utils/deprecation.py:172\u001B[39m, in \u001B[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    168\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m minimum_action \u001B[38;5;129;01min\u001B[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torchdynamo_compiling():\n\u001B[32m    169\u001B[39m     \u001B[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001B[39;00m\n\u001B[32m    170\u001B[39m     warnings.warn(message, \u001B[38;5;167;01mFutureWarning\u001B[39;00m, stacklevel=\u001B[32m2\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m172\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/proj/ciptmp/du69limo/to/rag-qa/.venv/lib/python3.13/site-packages/transformers/models/t5/modeling_t5.py:529\u001B[39m, in \u001B[36mT5Attention.forward\u001B[39m\u001B[34m(self, hidden_states, mask, key_value_states, position_bias, past_key_values, layer_head_mask, query_length, use_cache, output_attentions, cache_position)\u001B[39m\n\u001B[32m    526\u001B[39m             past_key_values.is_updated[\u001B[38;5;28mself\u001B[39m.layer_idx] = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m    528\u001B[39m \u001B[38;5;66;03m# compute scores, equivalent of torch.einsum(\"bnqd,bnkd->bnqk\", query_states, key_states), compatible with onnx op>9\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m529\u001B[39m scores = \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmatmul\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery_states\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey_states\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtranspose\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m2\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    531\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m position_bias \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    532\u001B[39m     key_length = key_states.shape[-\u001B[32m2\u001B[39m]\n",
      "\u001B[31mOutOfMemoryError\u001B[39m: CUDA out of memory. Tried to allocate 864.00 MiB. GPU 0 has a total capacity of 7.58 GiB of which 854.50 MiB is free. Including non-PyTorch memory, this process has 6.71 GiB memory in use. Of the allocated memory 6.54 GiB is allocated by PyTorch, and 32.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "from src.evaluate_rag_full import run_full_rag_eval\n",
    "\n",
    "run_full_rag_eval(config=config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
