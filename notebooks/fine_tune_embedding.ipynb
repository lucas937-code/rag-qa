{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1885c22567f3cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T19:41:53.529976Z",
     "start_time": "2025-11-29T19:41:53.500005Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using configuration: LocalConfig\n",
      "Base directory: /mnt/c/dev/ml/rag-qa\n",
      "âœ… Ensured directory exists: /mnt/c/dev/ml/rag-qa/.hf_cache\n",
      "âœ… Ensured directory exists: /mnt/c/dev/ml/rag-qa/data\n",
      "âœ… Ensured directory exists: /mnt/c/dev/ml/rag-qa/data/train\n",
      "âœ… Ensured directory exists: /mnt/c/dev/ml/rag-qa/data/validation\n",
      "âœ… Ensured directory exists: /mnt/c/dev/ml/rag-qa/data/test\n"
     ]
    }
   ],
   "source": [
    "from src.config import LocalConfig, ColabConfig, is_colab\n",
    "\n",
    "config = ColabConfig() if is_colab() else LocalConfig()\n",
    "\n",
    "print(\"Using configuration:\", type(config).__name__)\n",
    "print(\"Base directory:\", config.base_dir)\n",
    "\n",
    "config.ensure_dirs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e05490ab31fa4ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T18:56:56.091724Z",
     "start_time": "2025-11-29T18:40:17.272215Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/dev/ml/rag-qa/corpus_faiss.index.run1\n",
      "/mnt/c/dev/ml/rag-qa/corpus_passages.pkl.run1\n",
      "/mnt/c/dev/ml/rag-qa/corpus_embeddings_unique.pkl.run1\n",
      "Embeddings not found or force_recompute=True, computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading shards from /mnt/c/dev/ml/rag-qa/data/train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 129.92it/s]\n",
      "Loading shards from /mnt/c/dev/ml/rag-qa/data/validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 151.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 4000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting passages:   0%|          | 0/4000 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (9756 > 256). Running this sequence through the model will result in indexing errors\n",
      "Extracting passages: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4000/4000 [02:03<00:00, 32.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 143931 duplicate passages (226530 unique).\n",
      "Saved passages to /mnt/c/dev/ml/rag-qa/corpus_passages.pkl.run1\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 443/443 [03:30<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved embeddings to /mnt/c/dev/ml/rag-qa/corpus_embeddings_unique.pkl.run1\n",
      "Saved FAISS index to /mnt/c/dev/ml/rag-qa/corpus_faiss.index.run1 (dim=384, n=226530)\n",
      "Run 1 done. Built 226530 passages.\n",
      "/mnt/c/dev/ml/rag-qa/corpus_faiss.index.run2\n",
      "/mnt/c/dev/ml/rag-qa/corpus_passages.pkl.run2\n",
      "/mnt/c/dev/ml/rag-qa/corpus_embeddings_unique.pkl.run2\n",
      "Embeddings not found or force_recompute=True, computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading shards from /mnt/c/dev/ml/rag-qa/data/train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 141.90it/s]\n",
      "Loading shards from /mnt/c/dev/ml/rag-qa/data/validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 158.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 4000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting passages:   0%|          | 0/4000 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (9756 > 256). Running this sequence through the model will result in indexing errors\n",
      "Extracting passages: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4000/4000 [01:54<00:00, 34.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 115280 duplicate passages (181673 unique).\n",
      "Saved passages to /mnt/c/dev/ml/rag-qa/corpus_passages.pkl.run2\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 355/355 [03:32<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved embeddings to /mnt/c/dev/ml/rag-qa/corpus_embeddings_unique.pkl.run2\n",
      "Saved FAISS index to /mnt/c/dev/ml/rag-qa/corpus_faiss.index.run2 (dim=384, n=181673)\n",
      "Run 2 done. Built 181673 passages.\n",
      "/mnt/c/dev/ml/rag-qa/corpus_faiss.index.run3\n",
      "/mnt/c/dev/ml/rag-qa/corpus_passages.pkl.run3\n",
      "/mnt/c/dev/ml/rag-qa/corpus_embeddings_unique.pkl.run3\n",
      "Embeddings not found or force_recompute=True, computing embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading shards from /mnt/c/dev/ml/rag-qa/data/train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 78.61it/s]\n",
      "Loading shards from /mnt/c/dev/ml/rag-qa/data/validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 159.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 4000 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting passages:   0%|          | 0/4000 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (9756 > 256). Running this sequence through the model will result in indexing errors\n",
      "Extracting passages: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4000/4000 [01:49<00:00, 36.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 96231 duplicate passages (151826 unique).\n",
      "Saved passages to /mnt/c/dev/ml/rag-qa/corpus_passages.pkl.run3\n",
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 297/297 [03:23<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved embeddings to /mnt/c/dev/ml/rag-qa/corpus_embeddings_unique.pkl.run3\n",
      "Saved FAISS index to /mnt/c/dev/ml/rag-qa/corpus_faiss.index.run3 (dim=384, n=151826)\n",
      "Run 3 done. Built 151826 passages.\n",
      "\n",
      "Runs fertig. Starte nun evaluate_retrieve (DEV_LIMIT z.B. 200) pro Run, falls du die Artefakte getrennt hÃ¤ltst.\n"
     ]
    }
   ],
   "source": [
    "from src.config import Config\n",
    "from src.compute_embeddings import compute_embeddings\n",
    "\n",
    "chunk_settings = [\n",
    "    (160, 40),\n",
    "    (200, 50),\n",
    "    (240, 60),\n",
    "]\n",
    "\n",
    "MAX_SHARDS = 2\n",
    "DEV_RUNS = []\n",
    "\n",
    "FAISS_INDEX_FILE = config.faiss_index_file\n",
    "EMBEDDINGS_FILE = config.embeddings_file\n",
    "PASSAGES_FILE = config.passages_file\n",
    "\n",
    "for idx, (chunk_tokens, chunk_overlap) in enumerate(chunk_settings, start=1):\n",
    "    config.faiss_index_file = f\"{FAISS_INDEX_FILE}.run{idx}\"\n",
    "    config.embeddings_file = f\"{EMBEDDINGS_FILE}.run{idx}\"\n",
    "    config.passages_file = f\"{PASSAGES_FILE}.run{idx}\"\n",
    "    print(config.faiss_index_file)\n",
    "    print(config.passages_file)\n",
    "    print(config.embeddings_file)\n",
    "\n",
    "    corpus, emb = compute_embeddings(\n",
    "        config,\n",
    "        force_recompute=True,\n",
    "        recompute_passages=True,\n",
    "        data_dirs=[config.train_dir, config.val_dir],\n",
    "        max_shards_per_dir=MAX_SHARDS,\n",
    "        chunk_tokens=chunk_tokens,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "    )\n",
    "\n",
    "    print(f\"Run {idx} done. Built {len(corpus) if corpus else 0} passages.\")\n",
    "    DEV_RUNS.append((chunk_tokens, chunk_overlap))\n",
    "\n",
    "print(\"\\nRuns fertig. Starte nun evaluate_retrieve (DEV_LIMIT z.B. 200) pro Run, falls du die Artefakte getrennt hÃ¤ltst.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-29T19:03:09.806002Z",
     "start_time": "2025-11-29T19:02:19.626566Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus_faiss.index.run3\n",
      "ðŸ”¹ Loaded FAISS index with 151826 passages\n",
      "\n",
      "=== ðŸ”¥ Evaluating TRAIN â€” first 1000 samples ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading /mnt/c/dev/ml/rag-qa/data/train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [00:00<00:00, 164.15it/s]\n",
      "Evaluating Recall: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:16<00:00, 60.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@1: 0.6460\n",
      "Recall@3: 0.8440\n",
      "Recall@5: 0.8840\n",
      "Recall@7: 0.9080\n",
      "Recall@10: 0.9230\n",
      "\n",
      "=== ðŸ”¥ Evaluating VALIDATION â€” first 1000 samples ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading /mnt/c/dev/ml/rag-qa/data/validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 132.96it/s]\n",
      "Evaluating Recall: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:14<00:00, 69.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@1: 0.5490\n",
      "Recall@3: 0.7580\n",
      "Recall@5: 0.8070\n",
      "Recall@7: 0.8380\n",
      "Recall@10: 0.8700\n",
      "\n",
      "=== ðŸ”¥ Evaluating TEST â€” first 1000 samples ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading /mnt/c/dev/ml/rag-qa/data/test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 148.59it/s]\n",
      "Evaluating Recall: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:15<00:00, 65.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@1: 0.3600\n",
      "Recall@3: 0.5120\n",
      "Recall@5: 0.5630\n",
      "Recall@7: 0.6010\n",
      "Recall@10: 0.6300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from src.evaluate_retrieve import run_evaluation\n",
    "\n",
    "config.embeddings_file = f\"corpus_embeddings_unique.pkl.run3\"\n",
    "config.passages_file = f\"corpus_passages.pkl.run3\"\n",
    "config.faiss_index_file = f\"corpus_faiss.index.run3\"\n",
    "run_evaluation(config=config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
